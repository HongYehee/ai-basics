# ğŸ›© í…ì„œí”Œë¡œìš°ë¡œ ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ì´ˆ

## ì¶œì²˜
- ë„¤ì´ë²„ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ê³µê°œê°•ì˜ https://www.boostcourse.org/ai212/joinLectures/25072
- ê¹ƒí—ˆë¸Œ ì‹¤ìŠµ ì½”ë“œ https://github.com/deeplearningzerotoall/TensorFlow

## í•™ìŠµ ê¸°ê°„
- 2024.11.06 ~

## ëª©ì°¨
### PART 1ï¸âƒ£ Basic Machine Learning  
- [ ] Lec 01: ê¸°ë³¸ì ì¸ Machine Learningì˜ ìš©ì–´ì™€ ê°œë… ì„¤ëª…  
â¬œ Lec 02: Simple Linear Regression  
â¬œ Lab 02: Simple Linear Regressionë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lec 03: Linear Regression and How to minimize cost  
â¬œ Lab 03: Linear Regression and How to minimize costë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lec 04: Multi-variable Linear Regression  
â¬œ Lab 04: Multi-variable Linear Regressionë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lec 05-1: Logistic Regression/Classificationì˜ ì†Œê°œ  
â¬œ Lec 05-2: Logistic Regression/Classificationì˜ cost í•¨ìˆ˜, ìµœì†Œí™”  
â¬œ Lab 05-3: Logistic Regression/Classificationë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lec 06-1: Softmax Regression: ê¸°ë³¸ ê°œë… ì†Œê°œ  
â¬œ Lec 06-2: Softmax Classifierì˜ cost í•¨ìˆ˜  
â¬œ Lab 06-1: Softmax classifierë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lab 06-2: Fancy Softmax classifierë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê¸°  
â¬œ Lab 07-1: Application & Tips: í•™ìŠµë¥ (Learning Rate)ê³¼ ë°ì´í„° ì „ì²˜ë¦¬(Data Preprocessing)  
â¬œ Lab 07-2-1: Application & Tips: ì˜¤ë²„í”¼íŒ…(Overfitting) & Solutions  
â¬œ Lab 07-2-2: Application & Tips: í•™ìŠµë¥ , ì „ì²˜ë¦¬, ì˜¤ë²„í”¼íŒ…ì„ TensorFlowë¡œ ì‹¤ìŠµ  
â¬œ Lab 07-3-1: Application & Tips: Data & Learning  
â¬œ Lab 07-3-2: Application & Tips: ë‹¤ì–‘í•œ Datasetìœ¼ë¡œ ì‹¤ìŠµ  
  
### PART 2ï¸âƒ£: Basic Deep Learning  
â¬œ Lec 08-1: ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…: ì‹œì‘ê³¼ XOR ë¬¸ì œ  
â¬œ Lec 08-2: ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë… 2: Back-propagation ê³¼ 2006/2007 'ë”¥'ì˜ ì¶œí˜„  
â¬œ Lec 09-1: XOR ë¬¸ì œ ë”¥ëŸ¬ë‹ìœ¼ë¡œ í’€ê¸°  
â¬œ Lec 09-2: ë”¥ë„·íŠ¸ì› í•™ìŠµ ì‹œí‚¤ê¸° (backpropagation)  
â¬œ Lab 09-1: Neural Net for XOR  
â¬œ Lab 09-2: Tensorboard (Neural Net for XOR)  
â¬œ Lab 10-1: Sigmoid ë³´ë‹¤ ReLUê°€ ë” ì¢‹ì•„  
â¬œ Lab 10-2: Weight ì´ˆê¸°í™” ì˜í•´ë³´ì  
â¬œ Lab 10-3: Dropout  
â¬œ Lab 10-4: Batch Normalization  
  
### PART 3ï¸âƒ£: Convolutional Neural Network  
â¬œ Lec 11-1: ConvNetì˜ Conv ë ˆì´ì–´ ë§Œë“¤ê¸°  
â¬œ Lec 11-2: ConvNet Max pooling ê³¼ Full Network  
â¬œ Lec 11-3: ConvNetì˜ í™œìš© ì˜ˆ  
â¬œ Lab 11-0-1: CNN Basic: Convolution  
â¬œ Lab 11-0-2: CNN Basic: Pooling  
â¬œ Lab 11-1: mnist cnn keras sequential eager  
â¬œ Lab 11-2: mnist cnn keras functional eager  
â¬œ Lab-11-3: mnist cnn keras subclassing eager  
â¬œ Lab-11-4: mnist cnn keras ensemble eager  
â¬œ Lab-11-5: mnist cnn best keras eager  
  
### PART 4ï¸âƒ£: Recurrent Neural Network  
â¬œ Lec 12: NNì˜ ê½ƒ RNN ì´ì•¼ê¸°  
â¬œ Lab 12-0: rnn basics  
â¬œ Lab 12-1: many to one (word sentiment classification)  
â¬œ Lab 12-2: many to one stacked (sentence classification, stacked)  
â¬œ Lab 12-3: many to many (simple pos-tagger training)  
â¬œ Lab 12-4: many to many bidirectional (simpled pos-tagger training, bidirectional)  
â¬œ Lab 12-5: seq to seq (simple neural machine translation)  
â¬œ Lab 12-6: seq to seq with attention (simple neural machine translation, attention)  
